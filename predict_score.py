import torch
import torch.nn as nn
import clip
from PIL import Image
import os  # æ–°å¢ï¼šç”¨æ–¼è™•ç†è·¯å¾‘

from feature_utils import get_one_hot_tags

# 1. å®šç¾©æ¨¡å‹æ¶æ§‹ (å¿…é ˆèˆ‡ train_DressGPT.py å®Œå…¨ä¸€è‡´)
class DressGPT(nn.Module):
    def __init__(self):
        super(DressGPT, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(527, 256), 
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
    def forward(self, x):
        return self.net(x)

# 2. é æ¸¬å‡½å¼ (æ”¹ç‚º Ensemble ç‰ˆæœ¬)
def get_prediction(image_path, user_tags):
    """
    ä½¿ç”¨ 5-Fold Ensemble æ¨¡å‹é€²è¡Œå¹³å‡é æ¸¬
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_dir = "./DressGPT_models"  # è¨­å®šæ¨¡å‹è³‡æ–™å¤¾è·¯å¾‘
    
    # A. æå–åœ–ç‰‡èˆ‡æ¨™ç±¤ç‰¹å¾µ (é€™éƒ¨åˆ†åªéœ€è¦åšä¸€æ¬¡ï¼Œä¸ç”¨é‡è¤‡åš 5 æ¬¡)
    # ---------------------------------------------------------
    clip_model, preprocess = clip.load("ViT-B/32", device=device)
    
    try:
        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    except Exception as e:
        print(f"âŒ åœ–ç‰‡è®€å–éŒ¯èª¤: {e}")
        return 0.0

    with torch.no_grad():
        # å–å¾— CLIP åœ–ç‰‡å‘é‡
        img_feat = clip_model.encode_image(image).to(torch.float32)
        img_feat /= img_feat.norm(dim=-1, keepdim=True) # æ­£è¦åŒ–
        
        # å–å¾—æ¨™ç±¤ One-hot å‘é‡
        tag_feat = get_one_hot_tags(user_tags).to(device).unsqueeze(0)
        
        # æ‹¼æ¥æˆæœ€çµ‚è¼¸å…¥ç‰¹å¾µ (527ç¶­)
        combined_feat = torch.cat([img_feat, tag_feat], dim=1)

    # B. è¼‰å…¥ 5 å€‹æ¨¡å‹ä¸¦é€²è¡Œé›†æˆé æ¸¬ (Ensemble Prediction)
    # ---------------------------------------------------------
    total_score = 0.0
    models_loaded = 0
    
    print(f"ğŸ”„ é–‹å§‹ 5-Fold Ensemble é æ¸¬...")
    
    for i in range(1, 6):
        model_path = os.path.join(model_dir, f"fold{i}.pth")
        
        if os.path.exists(model_path):
            # å»ºç«‹æ¨¡å‹å¯¦ä¾‹
            model = DressGPT().to(device)
            # è¼‰å…¥æ¬Šé‡
            model.load_state_dict(torch.load(model_path, map_location=device))
            model.eval() # è¨˜å¾—åˆ‡æ›åˆ°è©•ä¼°æ¨¡å¼
            
            with torch.no_grad():
                # é æ¸¬åˆ†æ•¸
                score = model(combined_feat).item()
                total_score += score
                models_loaded += 1
                print(f"   - Fold {i}: {score:.2f}") # é™¤éŒ¯ç”¨ï¼Œæƒ³çœ‹ç´°ç¯€å¯ä»¥æ‰“é–‹
        else:
            print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ {model_path}ï¼Œè·³éã€‚")

    # C. è¨ˆç®—å¹³å‡åˆ†æ•¸
    # ---------------------------------------------------------
    if models_loaded == 0:
        print("âŒ éŒ¯èª¤: æ²’æœ‰è¼‰å…¥ä»»ä½•æ¨¡å‹ï¼Œç„¡æ³•è©•åˆ†ï¼")
        return 0.0
    
    avg_score = total_score / models_loaded
    final_score = max(0, min(10, round(avg_score, 2))) # é™åˆ¶ç¯„åœ 0~10 ä¸¦å–å°æ•¸é»å¾Œå…©ä½
    
    print(f"âœ… æœ€çµ‚è©•åˆ†: {final_score} (åŸºæ–¼ {models_loaded} å€‹æ¨¡å‹çš„å¹³å‡)")
    
    return final_score