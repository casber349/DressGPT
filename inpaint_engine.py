import torch
from diffusers import StableDiffusionInpaintPipeline
from PIL import Image
import os

class InpaintEngine:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        model_id = "runwayml/stable-diffusion-inpainting"
        
        print(f"ğŸš€ æ­£åœ¨è¼‰å…¥ Inpaint æ¨¡å‹è‡³ {self.device}...")
        
        # ä½¿ç”¨ float16 ç¯€çœä¸€åŠé¡¯å­˜
        self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None # é—œé–‰å®‰å…¨æª¢æŸ¥ä»¥åŠ é€Ÿä¸¦é¿å…èª¤åˆ¤
        ).to(self.device)

        # é¡¯å­˜å„ªåŒ–ï¼šå¦‚æœé¡¯å­˜ä½æ–¼ 8GBï¼Œå•Ÿç”¨ä»¥ä¸‹è¨­å®š
        if self.device == "cuda":
            self.pipe.enable_attention_slicing()
            # self.pipe.enable_model_cpu_offload() # å¦‚æœé‚„æ˜¯ç‚¸é¡¯å­˜å†é–‹é€™è¡Œ

    def generate(self, image_path, mask_path, prompt, negative_prompt):
        # è®€å–åœ–ç‰‡
        init_image = Image.open(image_path).convert("RGB")
        mask_image = Image.open(mask_path).convert("RGB")
        
        # é€™è£¡ç¢ºä¿ç¸®æ”¾å› SD è¼ƒå¥½è™•ç†çš„å°ºå¯¸ï¼Œä¾‹å¦‚ (576, 1024) 
        # æˆ–æ˜¯å¦‚æœä½ é¡¯å­˜è¼ƒå°ï¼Œå¯ä»¥ç¸®æ”¾æˆ (448, 800)
        init_image = init_image.resize((576, 1024))
        mask_image = mask_image.resize((576, 1024))

        with torch.autocast("cuda"):
            # åŸ·è¡Œé‡ç¹ª
            output = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                image=init_image,
                mask_image=mask_image,
                num_inference_steps=30,
                strength=1.0,
                guidance_scale=7.0,
                padding_mask_crop=32
            ).images[0]
        
        return output.resize((576, 1024))