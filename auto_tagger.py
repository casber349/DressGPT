import torch
import clip
import pandas as pd

TAG_MAPS = {
    "gender": {
        "options": [
            "a photo of a man, masculine facial features, short hair, male person", 
            "a photo of a woman, feminine facial features, long hair, wearing makeup, female person"
        ],
        "labels": ["male", "female"]
    },
    "age": {
        "options": [
            "a young teenager or child under 18 years old", 
            "a trendy young adult in their 20s or 30s", 
            "a mature middle-aged person in their 40s or 50s", 
            "a white-haired elderly person or senior citizen"
        ],
        "labels": ["teenager", "adult", "middle-aged", "elderly"]
    },
    "body": {
        "options": [
            "a very skinny thin body type with slender arms", 
            "a fit muscular athletic body with defined shape", 
            "a large plus size heavy body type, overweight", 
            "a normal average body type, neither thin nor fat"
        ],
        "labels": ["skinny", "athletic", "plus_size", "average"]
    },
    "season": {
        "options": [
            "wearing sleeveless tank top, shorts, or light t-shirt for hot summer", 
            "wearing very thick puffer jacket, heavy wool coat, scarf and gloves for cold winter", 
            "wearing a light jacket, hoodie, sweater or long sleeve shirt for spring or autumn"
        ],
        "labels": ["summer", "winter", "spring/fall"]
    },
    "formal": {
        "options": [
            "wearing a professional business suit, tuxedo, blazer and tie", 
            "wearing casual everyday clothes, street wear, t-shirt or hoodie"
        ],
        "labels": ["formal", "casual"]
    }
}

def run_auto_tagging(ids_list, embedding_path):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    clip_model, _ = clip.load("ViT-B/32", device=device)
    
    # è¼‰å…¥ Embedding ä¸¦ç¢ºä¿æ˜¯ float32
    all_embeddings = torch.load(embedding_path, map_location=device)
    
    # é è¨ˆç®—æ¨™ç±¤å‘é‡
    tag_features = {}
    for attr, data in TAG_MAPS.items():
        with torch.no_grad():
            text_tokens = clip.tokenize(data["options"]).to(device)
            text_feats = clip_model.encode_text(text_tokens).to(torch.float32)
            text_feats /= text_feats.norm(dim=-1, keepdim=True)
            tag_features[attr] = text_feats

    tagged_results = []
    print("ğŸš€ æ­£åœ¨é‡æ–°ç²¾æº–åŸ·è¡Œè¦–è¦ºæ¨™è¨»...")

    for img_id in ids_list:
        if img_id not in all_embeddings: continue
        
        # å–å¾—åœ–ç‰‡å‘é‡ä¸¦è½‰ç‚º float32
        img_feat = all_embeddings[img_id].to(device).to(torch.float32)
        if img_feat.ndim == 1: img_feat = img_feat.unsqueeze(0)
        img_feat /= img_feat.norm(dim=-1, keepdim=True)

        res = {"id": img_id}
        for attr, text_feat in tag_features.items():
            # é€™è£¡ä¸ä½¿ç”¨ 100.0 å€ç‡ï¼Œç›´æ¥è¨ˆç®—åŸå§‹é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = (img_feat @ text_feat.T)
            top_idx = similarity.argmax().item()
            # æ ¹æ“šç´¢å¼•å°æ‡‰å›æˆ‘å€‘å®šç¾©çš„ç°¡å–®æ¨™ç±¤
            res[attr] = TAG_MAPS[attr]["labels"][top_idx]
            
        tagged_results.append(res)
        
    return pd.DataFrame(tagged_results)

import re
import torch.nn.functional as F
import image_to_embedding
import os

ENERGY_THRESHOLD_RATIO = 0.25

def infer_user_tags_via_neighbors(user_embed, csv_path, all_embeddings_path, k=10):
    """
    [God Mode] å®Œæ•´è¼¸å‡ºæ‰€æœ‰é„°å±…æ¨™ç±¤èˆ‡æ¬Šé‡è¨ˆç®—éç¨‹
    """
    df = pd.read_csv(csv_path)
    df['id'] = df['id'].astype(str)
    all_embeddings = torch.load(all_embeddings_path, map_location="cpu")
    
    ids = list(all_embeddings.keys())
    db_matrix = torch.stack([all_embeddings[i].flatten() for i in ids]).to(torch.float32)
    user_embed = user_embed.to(torch.float32).view(1, -1)
    
    # ç›¸ä¼¼åº¦è¨ˆç®—
    sims = F.cosine_similarity(user_embed, db_matrix)
    top_values, top_indices = torch.topk(sims.flatten(), k=min(k, len(ids)))
    
    tag_accumulator = {} 
    sim_sum_accumulator = {}

    print(f"\n" + "="*60)
    print(f"ğŸ•µï¸â€â™‚ï¸ [æ·±åº¦å¯©æ ¸] æ­£åœ¨åˆ†æç›¸ä¼¼åº¦å‰ {k} åçš„é„°å±…...")
    print(f"="*60)

    match_count = 0
    for i in range(len(top_indices)):
        idx = top_indices[i].item()
        sim = top_values[i].item()
        neighbor_id = str(ids[idx])
        
        # ID è™•ç†é‚è¼¯
        try:
            clean_id = neighbor_id.split('.')[0]
            lookup_id = str(int(clean_id)) if clean_id.isdigit() else clean_id
        except:
            lookup_id = neighbor_id

        match_rows = df[df['id'].astype(str) == lookup_id]
        if match_rows.empty:
            match_rows = df[df['id'].astype(str) == neighbor_id]

        if not match_rows.empty:
            match_count += 1
            row = match_rows.iloc[0]
            # å–å¾—è©²é„°å±…æ‰€æœ‰ pos_tags èˆ‡ neg_tags
            tags_str = f"{row.get('pos_tags', '')}, {row.get('neg_tags', '')}"
            matches = re.findall(r"\(([^:]+):([\d\.]+)\)", tags_str)
            
            print(f"ğŸ“ é„°å±… {i+1}: ID={lookup_id.zfill(4)} | ç›¸ä¼¼åº¦={sim:.4f}")
            print(f"   ğŸ“œ åŸå§‹æ¨™ç±¤: {tags_str}") # ç›´æ¥åˆ—å°å®Œæ•´å­—ä¸²ï¼Œä¸æˆªæ–·

            for tag, weight in matches:
                w = float(weight)
                # æ¬Šé‡ * ç›¸ä¼¼åº¦ ç´¯ç©
                tag_accumulator[tag] = tag_accumulator.get(tag, 0) + (w * sim)
                sim_sum_accumulator[tag] = sim_sum_accumulator.get(tag, 0) + sim
        else:
            print(f"âš ï¸ é„°å±… {neighbor_id} åœ¨ CSV ä¸­æ‰¾ä¸åˆ°ï¼Œè«‹æª¢æŸ¥ ID æ ¼å¼")

    print(f"\n" + "-"*60)
    print(f"ğŸ§® æ¢¯åº¦æ¬Šé‡è¨ˆç®—å ±å‘Š (User Tag Inference):")
    print(f"-"*60)
    
    final_results = []
    for tag in tag_accumulator:
        total_energy = tag_accumulator[tag] # é€™è£¡å·²ç¶“æ˜¯ w * sim çš„ç¸½å’Œ
        
        
        # åªæœ‰èƒ½é‡é”æ¨™çš„æ‰é€²å…¥ final_results
        if total_energy >= ENERGY_THRESHOLD_RATIO * k:
            weighted_avg = round(total_energy / sim_sum_accumulator[tag], 1)
            clamped_w = max(0.1, min(1.9, weighted_avg))
            final_results.append((tag, clamped_w))
            print(f"ä¿ç•™{(tag, clamped_w)}æ¨™ç±¤ã€‚æ¨™ç±¤ç¸½å¼·åº¦:{total_energy}")
        else:
            print(f"æ¨æ£„{tag}æ¨™ç±¤ã€‚æ¨™ç±¤ç¸½å¼·åº¦:{total_energy}")
    
    final_results.sort(key=lambda x: x[1], reverse=True)

    # --- åœ¨ auto_tagger.py çš„ return final_results å‰é¢åŠ å…¥ ---
    print("\n" + "!"*20 + " [æ ¸å¿ƒç®—æ³•è¨ºæ–·] " + "!"*20)
    print(f"ç¸½å…±åƒè€ƒäº† {match_count} å€‹é„°å±…ã€‚")
    print("æœ€çµ‚è¨ˆç®—å‡ºçš„ User Tags (æ¬Šé‡å·²å®Œæˆç›¸ä¼¼åº¦æ­¸ä¸€åŒ–):")
    for tag, weight in final_results:
        # é€™è£¡å°å‡ºæ‰€æœ‰åƒèˆ‡è¨ˆç®—çš„æ¨™ç±¤åŠå…¶æœ€çµ‚å¼·åº¦
        print(f" >> [æ¨™ç±¤]: {tag:15s} | [æœ€çµ‚æ¬Šé‡]: {weight}")
    print("!"*55 + "\n")

    return final_results

# --- çµ‚ç«¯æ©ŸåŸ·è¡Œæ¸¬è©¦ ---
if __name__ == "__main__":
    # è«‹åœ¨æ­¤è™•è¼¸å…¥ä½ æƒ³è¦æ¸¬è©¦çš„æœ¬åœ°åœ–ç‰‡è·¯å¾‘
    test_image_path = "my_gorgeous_friend.jpg" 
    db_csv = "dress_dataset.csv"
    db_emb = "image_embeddings.pt"

    if os.path.exists(test_image_path):
        print(f"ğŸš€ é–‹å§‹å°åœ–ç‰‡ {test_image_path} é€²è¡Œè‡ªå‹•æ‰“æ¨™...")
        
        # 1. æå– Embedding
        user_v = image_to_embedding.get_single_image_embedding(test_image_path)
        
        if user_v is not None:
            # 2. é€²è¡Œæ¨è«–
            inferred_tags = infer_user_tags_via_neighbors(user_v, db_csv, db_emb, k=8)
            
            print("\n" + "="*40)
            print(f"ğŸ“Š DressGPT è‡ªå‹•æ‰“æ¨™å ±å‘Š (19éšå¼·åº¦)")
            print("="*40)
            for tag, weight in inferred_tags:
                # æ¬Šé‡é«˜æ–¼ 1.0 çš„æ¨™ç±¤é€šå¸¸æ˜¯é¡¯æ€§ç‰¹å¾µ
                star = "â˜…" if weight > 1.2 else " "
                print(f"{star} {tag:18s} : {weight:.2f}")
            print("="*40)
        else:
            print("âŒ ç„¡æ³•æå–åœ–ç‰‡ç‰¹å¾µã€‚")
    else:
        print(f"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦åœ–ç‰‡: {test_image_path}")